%!TEX root=./paper.tex

\chapter{Implementation}\label{chapter:implementation}

We implemented chopped symbolic execution into \toolname, an extension
to the KLEE symbolic execution
engine~\cite{klee}.\footnote{http://url-omitted-for-double-blind-revision}
Our KLEE extension starts from commit~\code{b2f93ff}.
Our implementation, which includes various static analyses
and an extension to the symbolic execution engine,
consists of 4500 lines of C++ code.
A user can run \toolname by
specifying the list of functions to skip along with specific call
sites via command-line switches.

\section{Static Analysis}
Our tool combines static analysis---in
particular mod-ref analysis and slicing---along with symbolic
execution. Since KLEE operates on LLVM bitcode, we rely on libraries
that statically analyze LLVM bitcode.
In particular, we implemented a code base for static analyses that exposes APIs to KLEE, so new or
better static analyses can be integrated in \toolname with ease.

\subsection{Mod-Ref Analysis}
We compute \textit{mod-ref analysis} by using the pointer analysis
provided by SVF~\cite{sui2016svf}. In particular, we rely on a
flow-insensitive and context-insensitive pointer analysis based on the
Andersen algorithm~\cite{andersen:pointeranalysis}.
Based on the pointer analyses results,
we compute an approximation of the control flow graph
which is used while computing the side effects of a given function.
The \textit{modifies}-set of a function $f$ is computed
by collecting the points-to information of all the $store$ instructions of the functions which
are reachable from $f$, according the our approximated control flow graph.
As for the \textit{ref}-set of $f$, we first identify all the call sites of $f$
and the collect the points-to information from all the $load$ instructions which are reachable
from these call sites (again, according the the approximated control flow graph).
The side effects of $f$ are given by the intersection of the \textit{modifies}-set and the \textit{ref}-set.

\subsection{Static Slicing}
We compute static backward slicing using the DG static slicer~\cite{dg}.
A static slicing criterion is given by a line and a set of variables.
In DG, the slicing criterion is can expressed by placing a call site with parameters.
The call site corresponds to the line and the parameters correspond to the variables.
A \textit{load} instruction which dependends on the side effects of a skipped function
is associated with the \textit{store} instructions which may modify the relevant memory location.
Each such \textit{store} instruction is annotated with a call to a unique function,
which is passed as a criterion for the static slicer.
We modified the slicer to be able to generate slices of arbitrary functions and not
only of the entry point of the program. Note that static slicing is
computed on-demand, only when a recovery is required. The same slice
may be reused for multiple recoveries, so each slice is computed only
once.

\subsection{Inlining}
Since our pointer analysis is context-insensitive,
inlining common functions (mostly, library functions) can result in better precision.
The inlining is prefromed only in the functions which are reachable from any skipped function.
This partial inlining prevents to code from growing too much.
A user can specifiy the functions for inlining via a command line option.

\subsection{Handling Non Void Functions}
If all the skipped funtions would have no return value,
the we were able to run the mod-ref analysis by inspecting only \textit{load} and \textit{store} instructions.
Unfortunately, that is not the situation in practice.
In order to handle this, we perform a reduction from a returning function to a non-returning function.
Suppose that we have the following returning function:
\begin{lstlisting}[linewidth=.4\textwidth,numbers=none]
int f(int x, int y) {
    return x + y;
}
\end{lstlisting}
\label{fig:ret2void-original}
We create a wrapper non-returning function $wf$ as follows:
\begin{lstlisting}[linewidth=.4\textwidth,numbers=none]
void wf(int *result, int x, int y) {
    *result = f(x, y);
}
\end{lstlisting}
\label{fig:ret2void-original}
Once we have the wrapper function, we replace the calls for $f$ with calls for $wf$.
If the original usage of $f$ was:
\begin{lstlisting}[linewidth=.4\textwidth,numbers=none]
int z = f(x, y);
\end{lstlisting}
then it is rewritten to:
\begin{lstlisting}[linewidth=.4\textwidth,numbers=none]
int result;
wf(&result, x, y);
int z = result;
\end{lstlisting}
We implemented an LLVM pass which does these rewritings automatically.

\section{Symbolic Execution}
In order to have \textit{recovery} and \textit{normal} states,
we extended the symbolic execution state
and added additional properties: \textit{guiding constraints, owset, allocation record}, \etc (see~\Cref{chapter:design}).
When the slicing of a function $f$ is required,
we create an inclusive clone of $f$ (considering the reachable functions from $f$).
The slicing is performed on the cloned functions, which are later added dynamically to KLEE's functions.
We modified the handling of the \textit{call} instruction,
such that we would be able to inject calls to the sliced functions as well as to the original ones.


\subsection{State Exploration}
\toolname also implements its own state
prioritization algorithm, \textit{chopped-aware search heuristic},
which favors the execution of normal states over recovery ones as
discussed in \S~\ref{Se:Search}. The algorithm is implemented as a
\textit{state searcher}, an abstraction used by KLEE to encapsulate
the state exploration logic. This implementation strategy also allows
us to be search-heuristic agnostic, meaning that our prioritization
strategy is compatible and can be combined with all present and future
search heuristics of KLEE.

\section{Limitations}
The current main limitation of \toolname is
the handling of symbolic addresses. Handling a symbolic address in
\toolname is not trivial, as it may refer to multiple allocation sites
and in turn lead to the recovery of several different skipped
functions. Moreover, symbolic addresses also increase the complexity
of interpreting load instructions. In case of a load instruction,
\toolname needs a concrete address to update in the dependent state
the addresses written during recovery, as discussed in \Cref{chapter:design}.

Chopped symbolic execution currently focuses on skipping functions.
However, the approach is more generic: In theory, we could skip any
arbitrary code portion that preserves the control-flow of the
program. We are currently working on relaxing the implementation of
\toolname to support such feature, and on designing an appropriate API
for specifying such arbitrary code portions.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
