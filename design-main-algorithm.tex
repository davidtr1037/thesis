%!TEX root=./paper.tex


\section{Main Algorithm}

\input{cse-alg}

\Cref{fig:chopped-symbexe} presents the key steps in chopped
symbolic execution, which we gradually explain. The algorithm operates
on a simple imperative C-like heap-manipulating language with
assignments, assertions, conditional jumps, dynamic memory allocation
and reclamation, and function calls with call-by-value parameter
passing.\footnote{In practice, our algorithm operates on LLVM
  bitcode~\cite{llvm}.}  Functions may have pointer parameters. Thus,
without loss of generality, we assume that functions do not have a
return value.\footnote{A function with a return value can always be
  rewritten with an additional parameter that points to the memory
  location of the return value.}  To simplify the explanation, we now
assume that we may skip at most one function invocation at every
explored path, and discuss the general case in
\S\ref{Se:SkipMultipleFuncs}. For the same reason, we also assume that
the program does not dynamically allocate memory, and discuss the
handling of $\code{malloc}$ and $\code{free}$ in \S\ref{Se:Malloc}.

Chopped symbolic execution begins by invoking procedure $\textsc{cse}$
with an \emph{initial symbolic state} ($\instate$) and a set
containing the names of the functions that the user wishes to skip
($\skipFunctions$). We expect a symbolic state $\workstate$ to encode,
among other properties, the next instruction to be executed (denoted
by $\Call{instruction}{\workstate}$), the activation record stack, and
a (symbolic) description of the program \emph{heap}. For example, the
chopped symbolic execution described in \Cref{chapter:overview} begins
with $\instate$ in which the stack contains only the activation record
of $\code{main}$, with the program counter at
line~\ref{line:main_enter}, an empty heap, and
$\skipFunctions = \{ \code{f} \}$.

At the beginning of the algorithm the $\worklist$ is empty, and we
initialize it with $\instate$ (\cref{alg:seed-worklist}). Then, a
standard worklist-based algorithm starts executing until either the
worklist is empty (\cref{alg:iterate-worklist}), or the algorithm
exhausts the time budget (elided). As usual, the algorithm pops the
symbolic state $\workstate$ to explore out of the worklist
(\cref{alg:pop-worklist}). Unconventionally, however, we assume that
the selected state is not suspended, as suspended states are blocked
until the value of the depended load is resolved (see
\S\ref{chapter:overview}).\footnote{For simplicity, we defer the
  discussion regarding the search heuristics to \S\ref{Se:Search}, and
  assume, for now, that any unsuspended state can be returned.}  The
next step of the algorithm depends on the instruction type
(\cref{alg:switch}).

\subsection{\text{Handling \textit{Call} Instructions}}
%{(lines~\ref{alg:casecall-begin}--\ref{alg:casecall-end})}}

A $\instruct{Call}$ instruction is handled as illustrated by step
\step{1} in \Cref{fig:simple} (see \S\ref{chapter:overview}): First, the
algorithm determines the name $f$ of the invoked function
(\cref{alg:call-find-target}). Then, if $f$ is one of the skipped
functions, the algorithm creates a snapshot of the current state
$\workstate$ and advances the program counter in $\workstate$
(\cref{alg:take-snapshot}); records the $\snapshot$ state at the end
of its list of \emph{skipped invocations}
(\cref{alg:record-snapshot}); and returns $\workstate$ to the worklist
(\cref{alg:push-worklist-call}). A skipped invocation is represented
as a triple $(f,\snapshot,\owset)$ composed of the name of a skipped
function $f$, a $snapshot$ of the symbolic state at the time $f$ was
skipped, and a set of the addresses $\owset$ subsequently overwritten
(initially empty).

Conversely, if $f$ should not be skipped, the algorithm handles its
invocation as usual in symbolic execution.  For brevity, we elide the
standard handling of commands by symbolic execution.

\subsection{\text{Handling \textit{Load} Instructions}}
%{(lines~\ref{alg:caseload-begin}--\ref{alg:caseload-end})}

Chopped symbolic execution utilizes
$\Call{mayMod}{\workstate,\workstate.\skipped,\addr}$, shown in
\Cref{fig:aux-func-may-mod} and explained in
\S\ref{Se:IdentifyingLoads}, to determine whether the address from
which a value is read ($\addr$) might have been modified by one of the
skipped functions on the path followed by the current state
$\workstate$. If so, the algorithm generates recovery states by
calling $\Call{recover}{\workstate,\addr}$.  Otherwise, the
$\instruct{Load}$ instruction is handled as usual in symbolic
execution (\cref{alg:load-normal}).

Procedure \textsc{createRecoveryState} is shown in
\ref{fig:aux-func-recS}. The function handles $\instruct{Load}$
instructions as illustrated by step \step{2}{} in \Cref{fig:simple}
(see \S\ref{chapter:overview}): It iterates over the list of skipped
functions (\Cref{alg:recover-foreach}), and uses
$\Call{mayMod}{\workstate, f, \addr}$ to determine which of the skipped
functions $f$ might have modified the dependent address. Once it finds
such a function (\cref{alg:recover-if-found}), the current state
becomes a dependent state (\cref{alg:recover-gen-depS}) and it is
immediately suspended (\cref{alg:recover-suspend}). The procedure then
generates the corresponding \emph{recovery state} $\recoveryState$ by
forking $\snapshot$ and by augmenting its path condition with the
guiding constraints $\gc$ (\cref{alg:recover-get-gc}), \ie the path
conditions accumulated in $\workstate$ since the snapshot state was
created (\cref{alg:recover-gen-recS,alg:recover-set-is-recS}). The
algorithm then invokes a static program slicer to remove from the
skipped function $f$ instructions which cannot affect the address of
the dependent load (\cref{alg:recover-slice}); records that
$\recoveryState$ was spawned to determine the value written in address
$\addr$ of $\dependentState$ (\cref{alg:recover-record-dep}); and
pushes the two states into the worklist
(\cref{alg:push-worklist-recovery}).

\subsection{\text{Handling \textit{Branch} Instructions}}
%{(lines~\ref{alg:casebranch-begin}--\ref{alg:casebranch-end})}

The algorithm checks whether the current state $\workstate$ is a
recovery state. If so, then the $\instruct{Branch}$ instruction is
handled as illustrated by steps \step{4}{} and \step{5}{} in
\Cref{fig:simple} (see \S\ref{chapter:overview}): It first extracts from
the worklist the (suspended) dependent state $\dependentState$, which
spawned $\workstate$ as a recovery state
(\cref{alg:extract-dependent}).  It then determines the branch
condition $\varphi$ (\cref{alg:branch-get-cond}); forks both the
current (recovery) state $\workstate$ and the dependent state
$\dependentState$, and adds $\varphi$ to their path condition
(lines~\ref{alg:branch-fork-true1}--\ref{alg:branch-fork-true2}).
After the fork, it checks whether the resulting states are feasible,
\ie their path conditions are satisfiable
(\cref{alg:branch-feasible-true}), and if so, adds them to the
worklist. If either one is not feasible, the newly forked recovery and
dependent states are simultaneously discarded
(\cref{alg:push-worklist-true-branch}).
Lines~\ref{alg:branch-fork-true1}--\ref{alg:push-worklist-true-branch}
act similarly to
lines~\ref{alg:branch-fork-false1}--\ref{alg:push-worklist-false-branch},
except that we use the negation of the branch condition
$\neg\varphi$. If the current state $\workstate$ is not a recovery
state, then the $\instruct{Branch}$ instruction is handled as usual in
symbolic execution (\cref{alg:branch-normal}).

\subsection{\text{Handling \textit{Store} Instructions}}
%{(lines~\ref{alg:casestore-begin}--\ref{alg:casestore-end})}

The algorithm executes the $\instruct{Store}$ instruction on the
current state in two steps. First, it updates the set of overwritten
addresses of the skipped function to record that a value was stored in
$\addr$ after the skip, and thus any value they may write is no longer
relevant (\cref{alg:record-overwrite}). Lastly, the symbolic state
$\workstate$ is updated as usual in symbolic execution
(\cref{alg:store-normal}). If $\workstate$ is a recovery state, then
the algorithm invokes
\Call{udpateDependentStates}{$\workstate, \addr$} (code elided) to
updated the dependent state (as illustrated by step \step{6}{} in
\Cref{fig:simple}, see \S\ref{chapter:overview}). In addition, it also
updates the set of overwritten addresses in the list of skipped
invocations of the dependent state. Note that
\Call{udpateDependentStates}{$\dependentState, \inst$} updates, but
does not resume, the dependent state.

\subsection{\text{Handling \textit{Exit} Instructions}}
%{(lines~\ref{alg:caseexit-begin}--\ref{alg:caseexit-end})}

The algorithm checks whether the current state $\workstate$ is a
recovery state. If $\workstate$ is a recovery state \emph{and} the
$\instruct{Exit}$ instruction is invoked inside the skipped function,
then the recovery is terminated and the instruction is handled as
illustrated by step \step{7}{} in \Cref{fig:simple} (see
\S\ref{chapter:overview}): Specifically, the recovery state itself if
discarded (\cref{alg:exit-terminate-recovery}) and the dependent state
is resumed \cref{alg:exit-resume}. Otherwise, the $\instruct{Exit}$
instruction is handled as usual in symbolic execution
(\cref{alg:exit-normal}).


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
